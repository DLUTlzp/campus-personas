{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/train.csv\", sep=\"###__###\",header = None,encoding='utf-8')\n",
    "# test = pd.read_csv(\"./data/test.csv\", sep=\"###__###\",header = None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22DD920316420BE2DF8D6EE651BA174B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>43CC3AF5A8D6430A3B572337A889AFE4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>E97654BFF5570E2CCD433EA6128EAC19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6931EFC26D229CCFCEA125D3F3C21E57</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>E780470C3BB0D340334BD08CDCC3C71A</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Age  Gender  Education  \\\n",
       "0  22DD920316420BE2DF8D6EE651BA174B    1       1          4   \n",
       "1  43CC3AF5A8D6430A3B572337A889AFE4    2       1          3   \n",
       "2  E97654BFF5570E2CCD433EA6128EAC19    4       1          0   \n",
       "3  6931EFC26D229CCFCEA125D3F3C21E57    4       2          3   \n",
       "4  E780470C3BB0D340334BD08CDCC3C71A    2       2          4   \n",
       "\n",
       "                                               query  \n",
       "0  柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...  \n",
       "1  广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...  \n",
       "2  钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...  \n",
       "3  最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...  \n",
       "4  干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = ['ID','Age','Gender','Education','query']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query('Age > 0 and Gender > 0 and Education > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def extra(text):\n",
    "    tokenized_words = []\n",
    "    for query in text.split('\\t'):\n",
    "        tokenized_query = [w if w != ' ' else '<BLANK>'\n",
    "                               for w in jieba.lcut(query)]\n",
    "#         tokenized_query += ['<EOS>']\n",
    "        tokenized_words.extend(tokenized_query)\n",
    "    return' '.join(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_num(text):\n",
    "    return len(text.split('\\t'))\n",
    "train['search_num'] = train['query'].map(lambda x:get_search_num(x))\n",
    "train['text_len'] = train['query'].map(lambda x:len(x.replace('\\t','')))\n",
    "train['text_avg_len'] = train['text_len']/train['search_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\LZP\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.681 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "train['query'] = train['query'].map(lambda x:extra(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "word_vec = TfidfVectorizer(analyzer='word',\n",
    "            ngram_range=(1,2),#(1,3)\n",
    "            min_df=3,  # 4  5\n",
    "            max_df=0.9, # 0.95 1.0 \n",
    "            use_idf=True,\n",
    "            smooth_idf=True, \n",
    "            sublinear_tf=True)\n",
    "train_term_doc = word_vec.fit_transform(train['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70793 17699\n",
      "-----Age:第0次-----\n",
      "validation score is 0.61325498615741\n",
      "70793 17699\n",
      "-----Age:第1次-----\n",
      "validation score is 0.6172100118650771\n",
      "70794 17698\n",
      "-----Age:第2次-----\n",
      "validation score is 0.6197310430557125\n",
      "70794 17698\n",
      "-----Age:第3次-----\n",
      "validation score is 0.6148152333597017\n",
      "70794 17698\n",
      "-----Age:第4次-----\n",
      "validation score is 0.6104644592609334\n",
      "70793 17699\n",
      "-----Gender:第0次-----\n",
      "validation score is 0.8441719871179163\n",
      "70793 17699\n",
      "-----Gender:第1次-----\n",
      "validation score is 0.8476185095203119\n",
      "70794 17698\n",
      "-----Gender:第2次-----\n",
      "validation score is 0.8407729686970279\n",
      "70794 17698\n",
      "-----Gender:第3次-----\n",
      "validation score is 0.8442196858402079\n",
      "70794 17698\n",
      "-----Gender:第4次-----\n",
      "validation score is 0.8431461182054469\n",
      "70793 17699\n",
      "-----Education:第0次-----\n",
      "validation score is 0.6390756539917509\n",
      "70793 17699\n",
      "-----Education:第1次-----\n",
      "validation score is 0.6376631448104413\n",
      "70794 17698\n",
      "-----Education:第2次-----\n",
      "validation score is 0.6380381964063736\n",
      "70794 17698\n",
      "-----Education:第3次-----\n",
      "validation score is 0.6341394507853995\n",
      "70794 17698\n",
      "-----Education:第4次-----\n",
      "validation score is 0.6380381964063736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "label_arr = {'Gender':2,'Age':6,'Education':6}\n",
    "for label in label_arr.keys():\n",
    "    for i,(train_index,eval_index) in enumerate(kf.split(train_term_doc)):\n",
    "        print(len(train_index),len(eval_index))\n",
    "\n",
    "        lb = LabelEncoder()\n",
    "        train[label] = lb.fit_transform(train[label].tolist())\n",
    "        #训练集\n",
    "        X_train = train_term_doc[train_index]\n",
    "        y_train = train[label][train_index]\n",
    "\n",
    "        #验证集\n",
    "        X_eval = train_term_doc[eval_index]\n",
    "        y_eval = train[label][eval_index]\n",
    "\n",
    "        model = LogisticRegression(C=4, dual=True) \n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        ####对于验证集进行预测\n",
    "        train_matrix = np.zeros((train.shape[0],label_arr[label]))\n",
    "        eval_prob = model.predict_proba(X_eval)\n",
    "        train_matrix[eval_index] = eval_prob.reshape((X_eval.shape[0], label_arr[label]))#array\n",
    "\n",
    "        eval_pred = np.argmax(eval_prob,axis=1)\n",
    "        eval_pred = lb.inverse_transform(eval_pred)\n",
    "        score = metrics.accuracy_score(lb.inverse_transform(y_eval),eval_pred)\n",
    "        \n",
    "        ###保存模型和数据\n",
    "        \n",
    "#         model.save\n",
    "#         cv_scores.append(score)\n",
    "        print(\"-----{}:第{}次-----\".format(label,i))\n",
    "        print(\"validation score is\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70793 17699\n",
      "[1]\tvalid_0's binary_logloss: 0.66014\n",
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.642805\n",
      "[3]\tvalid_0's binary_logloss: 0.629215\n",
      "[4]\tvalid_0's binary_logloss: 0.616363\n",
      "[5]\tvalid_0's binary_logloss: 0.605512\n",
      "[6]\tvalid_0's binary_logloss: 0.596151\n",
      "[7]\tvalid_0's binary_logloss: 0.586473\n",
      "[8]\tvalid_0's binary_logloss: 0.5775\n",
      "[9]\tvalid_0's binary_logloss: 0.570164\n",
      "[10]\tvalid_0's binary_logloss: 0.564121\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's binary_logloss: 0.564121\n",
      "(17699, 2)\n",
      "-----Gender:第0次-----\n",
      "validation score is 0.7427538278998813\n",
      "70793 17699\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-262a4938db95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m                    \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlgbm_metric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                   )\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m####对于验证集进行预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   1712\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1714\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1083\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m   1086\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ctypes.byref(self.handle)))\n\u001b[0;32m    882\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init_from_csr\u001b[1;34m(self, csr, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   1007\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1009\u001b[1;33m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "#sklearn api\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=666)\n",
    "label_arr = {'Gender':2,'Age':6,'Education':6}\n",
    "# label_arr = {'Age':6,'Gender':2,'Education':6}\n",
    "lgbm_class = {'Age':'multiclass','Gender':'binary','Education':'multiclass'}\n",
    "lgbm_metric = {'Age':'multi_logloss','Gender':'binary_logloss','Education':'multi_logloss'}\n",
    "for label in label_arr.keys():\n",
    "    for i,(train_index,eval_index) in enumerate(kf.split(train_term_doc)):\n",
    "        print(len(train_index),len(eval_index))\n",
    "\n",
    "        lb = LabelEncoder()\n",
    "        train[label] = lb.fit_transform(train[label].tolist())\n",
    "        #训练集\n",
    "        X_train = train_term_doc[train_index]\n",
    "        y_train = train[label][train_index]\n",
    "\n",
    "        #验证集\n",
    "        X_eval = train_term_doc[eval_index]\n",
    "        y_eval = train[label][eval_index]\n",
    "\n",
    "        model =lgb.LGBMClassifier(boosting_type='gbdt', \n",
    "                   num_leaves=2**5,\n",
    "                   max_depth=-1, \n",
    "                   learning_rate= 0.1,\n",
    "                   n_estimators=10,\n",
    "                   objective=lgbm_class[label],\n",
    "                   subsample=0.7,#\n",
    "                   colsample_bytree=0.5,#\n",
    "                   reg_lambda=10,#l2\n",
    "                   n_jobs=16, #\n",
    "#                    num_class=label_arr[label],#\n",
    "                   silent=True, \n",
    "                   random_state=2019,\n",
    "#                    class_weight=20,\n",
    "                   colsample_bylevel=0.5,\n",
    "                   min_child_weight=1.5,\n",
    "                   metric=lgbm_metric[label]\n",
    "                  )\n",
    "        model.fit(X_train,y_train,eval_set=(X_eval,y_eval), early_stopping_rounds=2)\n",
    "\n",
    "        ####对于验证集进行预测\n",
    "        train_matrix = np.zeros((train.shape[0],label_arr[label]))\n",
    "        eval_prob = model.predict_proba(X_eval)\n",
    "#         print(eval_prob.tolist())\n",
    "        print(eval_prob.shape)\n",
    "#         train_matrix[eval_index] = eval_prob..reshape((X_eval.shape[0], label_arr[label]))#array\n",
    "#         if label == 'Gender':\n",
    "#             eval_prob = eval_prob[0].reshape((label_arr[label],X_eval.shape[0])).T\n",
    "        eval_pred = np.argmax(eval_prob,axis=1)\n",
    "        eval_pred = lb.inverse_transform(eval_pred)\n",
    "        score = metrics.accuracy_score(lb.inverse_transform(y_eval),eval_pred)\n",
    "        \n",
    "        ###保存模型和数据\n",
    "        \n",
    "#         model.save\n",
    "#         cv_scores.append(score)\n",
    "        print(\"-----{}:第{}次-----\".format(label,i))\n",
    "        print(\"validation score is\",score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
